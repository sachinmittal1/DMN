{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from babi_loader import BabiDataset, pad_collate\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "task_id = 1\n",
    "batch_size=2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dset_train = BabiDataset(task_id)\n",
    "train_loader = DataLoader(\n",
    "dset_train, batch_size=batch_size, shuffle=False, collate_fn=pad_collate\n",
    ")\n",
    "\n",
    "\n",
    "for batch_idx, data in enumerate(train_loader):\n",
    "    contexts, questions, answers = data\n",
    "    batch_size = contexts.size()[0]\n",
    "    contexts = Variable(contexts.long())\n",
    "    questions = Variable(questions.long())\n",
    "    answers = Variable(answers)\n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "def interpret_indexed_tensor(var):\n",
    "    qa= dset_train.QA\n",
    "    if len(var.size()) == 3:\n",
    "        # var -> n x #sen x #token\n",
    "        for n, sentences in enumerate(var):\n",
    "            for i, sentence in enumerate(sentences):\n",
    "                s = ' '.join([qa.IVOCAB[elem.data[0]] for elem in sentence ] )\n",
    "                print(f'{n}th of batch, {i}th sentence, {s}')\n",
    "    elif len(var.size()) == 2:\n",
    "        # var -> n x #token\n",
    "        for n, sentence in enumerate(var):\n",
    "            s = ' '.join([qa.IVOCAB[elem.data[0]] for elem in sentence ] )\n",
    "            print(f'{n}th of batch, {s}')\n",
    "    elif len(var.size()) == 1:\n",
    "        # var -> n (one token per batch)\n",
    "        for n, token in enumerate(var):\n",
    "            s = qa.IVOCAB[token.data[0]]\n",
    "            print(f'{n}th of batch, {s}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contexts -> \n",
      "0th of batch, 0th sentence, mary moved to the bathroom . <EOS> <PAD>\n",
      "0th of batch, 1th sentence, john went to the hallway . <EOS> <PAD>\n",
      "0th of batch, 2th sentence, <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0th of batch, 3th sentence, <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1th of batch, 0th sentence, mary moved to the bathroom . <EOS> <PAD>\n",
      "1th of batch, 1th sentence, john went to the hallway . <EOS> <PAD>\n",
      "1th of batch, 2th sentence, daniel went back to the hallway . <EOS>\n",
      "1th of batch, 3th sentence, sandra moved to the garden . <EOS> <PAD>\n",
      "\n",
      "\n",
      " questions -> \n",
      "0th of batch, where is mary <EOS>\n",
      "1th of batch, where is daniel <EOS>\n",
      "\n",
      "\n",
      " answers -> \n",
      "0th of batch, bathroom\n",
      "1th of batch, hallway\n"
     ]
    }
   ],
   "source": [
    "#Demo\n",
    "print(\"contexts -> \")\n",
    "interpret_indexed_tensor(contexts)\n",
    "print(\"\\n\\n questions -> \")\n",
    "\n",
    "interpret_indexed_tensor(questions)\n",
    "print(\"\\n\\n answers -> \")\n",
    "\n",
    "interpret_indexed_tensor(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "var_sysout = sys.stdout\n",
    "\n",
    "# Disable\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Restore\n",
    "def enablePrint():\n",
    "    sys.stdout = var_sysout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will print\n",
      "This will too\n"
     ]
    }
   ],
   "source": [
    "#Demo\n",
    "# this will be used to enable or disable prints\n",
    "\n",
    "print ('This will print')\n",
    "\n",
    "blockPrint()\n",
    "\n",
    "print (\"This won't\")\n",
    "\n",
    "enablePrint()\n",
    "\n",
    "print (\"This will too\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 7,\n",
       " '<EOS>': 1,\n",
       " '<PAD>': 0,\n",
       " 'back': 14,\n",
       " 'bathroom': 6,\n",
       " 'bedroom': 20,\n",
       " 'daniel': 13,\n",
       " 'garden': 16,\n",
       " 'hallway': 10,\n",
       " 'is': 12,\n",
       " 'john': 8,\n",
       " 'journeyed': 18,\n",
       " 'kitchen': 21,\n",
       " 'mary': 2,\n",
       " 'moved': 3,\n",
       " 'office': 17,\n",
       " 'sandra': 15,\n",
       " 'the': 5,\n",
       " 'to': 4,\n",
       " 'travelled': 19,\n",
       " 'went': 9,\n",
       " 'where': 11}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa= dset_train.QA\n",
    "qa.VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(dset_train.QA.VOCAB)\n",
    "hidden_size = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def position_encoding(embedded_sentence):\n",
    "    \n",
    "    sentence_length = embedded_sentence.size()[2]\n",
    "    embedding_length = embedded_sentence.size()[3]\n",
    "    shape = (embedding_length, sentence_length)\n",
    "    l = np.empty(shape)\n",
    "\n",
    "    for word_index in range(sentence_length):\n",
    "        for e_index in range(embedding_length):\n",
    "            l[e_index][word_index]=(1 - word_index/(sentence_length-1)) - (e_index/(embedding_length-1)) * (1 - 2*word_index/(sentence_length-1))\n",
    "    l=l.T\n",
    "    l = torch.FloatTensor(l)\n",
    "    l = l.unsqueeze(0) # for #batch\n",
    "    l = l.unsqueeze(1) # for #sen\n",
    "    print(\"embedded_sentence.size() = \",embedded_sentence.size())\n",
    "    print(\"before \",(l.size()))\n",
    "    l = l.expand_as(embedded_sentence)\n",
    "    print(\"after \",(l.size()))\n",
    "    weighted = embedded_sentence * Variable(l)\n",
    "    var = torch.sum(weighted, dim=2).squeeze(2)\n",
    "    print(\"return size\", var.size())\n",
    "    return torch.sum(weighted, dim=2).squeeze(2) # sum with tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#it convers f to Òƒf\n",
    "def input_module(contexts, word_embedding):\n",
    "    gru = nn.GRU(hidden_size, hidden_size, bidirectional=True, batch_first=True)\n",
    "    for name, param in gru.state_dict().items():\n",
    "        if 'weight' in name: init.xavier_normal(param)\n",
    "\n",
    "    dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    \n",
    "    print(\"context dimension before word embedding\",contexts.size())\n",
    "    \n",
    "    batch_num, sen_num, token_num = contexts.size()\n",
    "    #print(\"before view \", contexts.size())\n",
    "    contexts = contexts.view(batch_num, -1)\n",
    "    #print(\"after view \", contexts.size())\n",
    "\n",
    "    contexts = word_embedding(contexts)\n",
    "    print(\"context dimension after word embedding\",contexts.size())\n",
    "\n",
    "    contexts = contexts.view(batch_num, sen_num, token_num, -1)\n",
    "\n",
    "    print(\"context dimension \",contexts.size())\n",
    "\n",
    "    contexts = position_encoding(contexts)\n",
    "    \n",
    "    contexts = dropout(contexts)\n",
    "    \n",
    "    print(\"contexts dimension after position_encoding = \", (contexts.size()))\n",
    "\n",
    "\n",
    "    h0 = Variable(torch.zeros(2, batch_num, hidden_size))\n",
    "    print(\"h0 size = \", (h0.size()))\n",
    "\n",
    "    facts, hdn = gru(contexts, h0)\n",
    "    print(\"facts size = \", (facts.size()))\n",
    "    print(\"hdn size = \",(hdn.size()))\n",
    "    facts = facts[:, :, :hidden_size] + facts[:, :, hidden_size:]\n",
    "    \n",
    "    print(\"final fact (context) size returned from input module\", facts.size())\n",
    "    return facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context dimension before word embedding torch.Size([2, 4, 8])\n",
      "context dimension after word embedding torch.Size([2, 32, 80])\n",
      "context dimension  torch.Size([2, 4, 8, 80])\n",
      "embedded_sentence.size() =  torch.Size([2, 4, 8, 80])\n",
      "before  torch.Size([1, 1, 8, 80])\n",
      "after  torch.Size([2, 4, 8, 80])\n",
      "return size torch.Size([2, 4, 80])\n",
      "contexts dimension after position_encoding =  torch.Size([2, 4, 80])\n",
      "h0 size =  torch.Size([2, 2, 80])\n",
      "facts size =  torch.Size([2, 4, 160])\n",
      "hdn size =  torch.Size([2, 2, 80])\n",
      "final fact (context) size returned from input module torch.Size([2, 4, 80])\n"
     ]
    }
   ],
   "source": [
    "#Demo\n",
    "\n",
    "word_embedding = nn.Embedding(vocab_size, hidden_size, padding_idx=0, sparse=True)\n",
    "\n",
    "facts=input_module(contexts,word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def question_module(questions, word_embedding):\n",
    "    '''\n",
    "    questions.size() -> (#batch, #token)\n",
    "    word_embedding() -> (#batch, #token, #embedding)\n",
    "    gru() -> (1, #batch, #hidden)\n",
    "    '''\n",
    "    \n",
    "    gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "    print(\"before \",(questions.size()))\n",
    "    questions = word_embedding(questions)\n",
    "    print(\"after word embedding \",(questions.size()))\n",
    "    _, questions = gru(questions)\n",
    "    print(\"after gru \",(questions.size()))\n",
    "\n",
    "    questions = questions.transpose(0, 1)\n",
    "    print(\"after transpose \",(questions.size()))\n",
    "\n",
    "    return questions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  torch.Size([2, 4])\n",
      "after word embedding  torch.Size([2, 4, 80])\n",
      "after gru  torch.Size([1, 2, 80])\n",
      "after transpose  torch.Size([2, 1, 80])\n"
     ]
    }
   ],
   "source": [
    "#Demo\n",
    "ques = question_module(questions, word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns attention vector g (containing scalar values) based on facts, questions and prevM\n",
    "\n",
    "z1 = nn.Linear(4 * hidden_size, hidden_size)\n",
    "z2 = nn.Linear(hidden_size, 1)\n",
    "init.xavier_normal(z1.state_dict()['weight'])\n",
    "init.xavier_normal(z2.state_dict()['weight'])\n",
    "\n",
    "def make_interaction(facts, questions, prevM):\n",
    "    '''\n",
    "    facts.size() -> (#batch, #sentence, #hidden = #embedding)\n",
    "    questions.size() -> (#batch, 1, #hidden)\n",
    "    prevM.size() -> (#batch, #sentence = 1, #hidden = #embedding)\n",
    "    z.size() -> (#batch, #sentence, 4 x #embedding)\n",
    "    G.size() -> (#batch, #sentence)\n",
    "    '''\n",
    "   \n",
    "    batch_num, sen_num, embedding_size = facts.size()\n",
    "    questions = questions.expand_as(facts)\n",
    "    prevM = prevM.expand_as(facts)\n",
    "\n",
    "    z = torch.cat([\n",
    "        facts * questions,\n",
    "        facts * prevM,\n",
    "        torch.abs(facts - questions),\n",
    "        torch.abs(facts - prevM)\n",
    "    ], dim=2)\n",
    "    print(\"z.size after concatenation \",z.size())\n",
    "    \n",
    "    z = z.view(-1, 4 * embedding_size)\n",
    "    print(\"z.size after view \",z.size())\n",
    "    G = F.tanh(z1(z))\n",
    "    G = z2(G)\n",
    "    print(\"G.size = \",G.size())\n",
    "    G = G.view(batch_num, -1)\n",
    "    print(\"G.size = \",G.size())\n",
    "\n",
    "    G = F.softmax(G)\n",
    "\n",
    "    return G\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z.size after concatenation  torch.Size([2, 4, 320])\n",
      "z.size after view  torch.Size([8, 320])\n",
      "G.size =  torch.Size([8, 1])\n",
      "G.size =  torch.Size([2, 4])\n",
      "Variable containing:\n",
      " 0.1932  0.2221  0.3125  0.2721\n",
      " 0.1375  0.1383  0.3666  0.3575\n",
      "[torch.FloatTensor of size 2x4]\n",
      "\n",
      "Variable containing:\n",
      " 0.3125\n",
      " 0.3666\n",
      "[torch.FloatTensor of size 2]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 2]\n",
      "\n",
      "0th of batch, 0th sentence, <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1th of batch, 0th sentence, daniel went back to the hallway . <EOS>\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinmittal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "#DEMO\n",
    "#calculating attention\n",
    "\n",
    "prevM=ques\n",
    "G=make_interaction(facts, ques, prevM)\n",
    "value, index = torch.max(G, dim=1)\n",
    "print(G)\n",
    "print(value)\n",
    "print(index)\n",
    "print(interpret_indexed_tensor(contexts[:, index[0], :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AGRUCell(fact, C, g):\n",
    "    #C is h_(i-1) i.e previous hidden state\n",
    "    input_size=hidden_size\n",
    "    Wr = nn.Linear(input_size, hidden_size)\n",
    "    init.xavier_normal(Wr.state_dict()['weight'])\n",
    "    Ur = nn.Linear(hidden_size, hidden_size)\n",
    "    init.xavier_normal(Ur.state_dict()['weight'])\n",
    "    W = nn.Linear(input_size, hidden_size)\n",
    "    init.xavier_normal(W.state_dict()['weight'])\n",
    "    U = nn.Linear(hidden_size, hidden_size)\n",
    "    init.xavier_normal(U.state_dict()['weight'])\n",
    "\n",
    "    r = F.sigmoid(Wr(fact) + Ur(C))\n",
    "    #print(\"r.size = \", r.size())\n",
    "    h_tilda = F.tanh(W(fact) + r * U(C))\n",
    "    #print(\"h_tilda.size = \", h_tilda.size())\n",
    "    print(\"g.size = \", g.size())\n",
    "    g = g.unsqueeze(1).expand_as(h_tilda)\n",
    "    print(\"g.size = \", g.size())\n",
    "\n",
    "    h = g * h_tilda + (1 - g) * C\n",
    "    return h\n",
    "\n",
    "#AttaintionGRU_forward\n",
    "def AGRU(facts, G):\n",
    "    batch_num, sen_num, embedding_size = facts.size()\n",
    "    C = Variable(torch.zeros(hidden_size)) #previous hidden state of GRU, initally zero\n",
    "    for sid in range(sen_num):\n",
    "        fact = facts[:, sid, :] #taking all batch facts at a time\n",
    "        print(\"fact.size() = \",fact.size())\n",
    "        g = G[:, sid]\n",
    "        print(\"g.size = \", g.size())\n",
    "        if sid == 0:\n",
    "            C = C.unsqueeze(0).expand_as(fact)\n",
    "            print(\"C.size = \",C.size())\n",
    "        C = AGRUCell(fact, C, g)\n",
    "        break #running only one time for demonstration purpose\n",
    "    return C #final hidden state of AGRU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fact.size() =  torch.Size([2, 80])\n",
      "g.size =  torch.Size([2])\n",
      "C.size =  torch.Size([2, 80])\n",
      "g.size =  torch.Size([2])\n",
      "g.size =  torch.Size([2, 80])\n",
      "torch.Size([2, 80])\n"
     ]
    }
   ],
   "source": [
    "#Demo\n",
    "#calculating last hidden state of attention gru\n",
    "C= AGRU(facts, G)  \n",
    "print(C.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memory(facts, questions, prevM):\n",
    "    next_mem = nn.Linear(3 * hidden_size, hidden_size)\n",
    "    init.xavier_normal(next_mem.state_dict()['weight'])\n",
    "    blockPrint()\n",
    "    G = make_interaction(facts, questions, prevM)\n",
    "    C = AGRU(facts, G)\n",
    "    enablePrint()\n",
    "    concat = torch.cat([prevM.squeeze(1), C, questions.squeeze(1)], dim=1)\n",
    "    print(\"concat.size() = \",concat.size())\n",
    "    next_mem = F.relu(next_mem(concat))\n",
    "    next_mem = next_mem.unsqueeze(1)\n",
    "    print(\"next_mem.size() = \",next_mem.size())\n",
    "    return next_mem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat.size() =  torch.Size([2, 240])\n",
      "next_mem.size() =  torch.Size([2, 1, 80])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinmittal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "#Demo\n",
    "#calculating next memory based on prevM, facts and questions\n",
    "next_mem=memory(facts, ques, prevM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_module(M, questions):\n",
    "    print(next_mem.size())\n",
    "    print(questions.size())\n",
    "    z = nn.Linear(2 * hidden_size, vocab_size)\n",
    "    init.xavier_normal(z.state_dict()['weight'])\n",
    "    dropout = nn.Dropout(0.1)\n",
    "    M = dropout(M)\n",
    "    concat = torch.cat([M, questions], dim=2).squeeze(1)\n",
    "    z = z(concat)\n",
    "    print(z.size())\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 22])\n",
      "vocab_size =  22\n"
     ]
    }
   ],
   "source": [
    "#Demo\n",
    "#calulating final answer based on question and last memory\n",
    "blockPrint()\n",
    "ans=answer_module(next_mem, ques)\n",
    "enablePrint()\n",
    "print(ans.size())\n",
    "print(\"vocab_size = \",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DMNPlus(nn.Module):\n",
    "    def __init__(self, hidden_size, vocab_size, num_hop=3, qa=None):\n",
    "        super(DMNPlus, self).__init__()\n",
    "        self.num_hop = num_hop\n",
    "        self.qa = qa\n",
    "        self.word_embedding = nn.Embedding(vocab_size, hidden_size, padding_idx=0, sparse=True)\n",
    "        init.uniform(self.word_embedding.state_dict()['weight'], a=-(3**0.5), b=3**0.5)\n",
    "        self.criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "\n",
    "        \n",
    "    def forward(self, contexts, questions):\n",
    "        '''\n",
    "        contexts.size() -> (#batch, #sentence, #token) -> (#batch, #sentence, #hidden = #embedding)\n",
    "        questions.size() -> (#batch, #token) -> (#batch, 1, #hidden)\n",
    "        '''\n",
    "        facts = input_module(contexts, self.word_embedding)\n",
    "        questions = question_module(questions, self.word_embedding)\n",
    "        M = questions\n",
    "        for hop in range(self.num_hop):\n",
    "            M = memory(facts, questions, M)\n",
    "        preds = answer_module(M, questions)\n",
    "        return preds\n",
    "\n",
    "    \n",
    "    def get_loss(self, contexts, questions, targets):\n",
    "        \n",
    "        blockPrint()\n",
    "        output = self.forward(contexts, questions)\n",
    "        enablePrint() \n",
    "        print(\"actual answers size = \", targets.size())\n",
    "        print(\"predicted answers size = \", output.size())\n",
    "\n",
    "        loss = self.criterion(output, targets)\n",
    "        print(\"loss size = \", loss.size())\n",
    "        print(\"loss  = \", loss)\n",
    "\n",
    "        reg_loss = 0\n",
    "        print(\"self.parameters() = \",self.parameters)\n",
    "        for param in self.parameters():\n",
    "            print(\"param.size()=\",param.size())\n",
    "            print(\"(param * param).size()=\",(param * param).size())\n",
    "            #regularisation\n",
    "            #param is embedding weight matrix\n",
    "            reg_loss += 0.001 * torch.sum(param * param)\n",
    "        preds = F.softmax(output)\n",
    "        _, pred_ids = torch.max(preds, dim=1)\n",
    "        print(pred_ids.size())\n",
    "        corrects = (pred_ids.data == answers.data)\n",
    "        acc = torch.mean(corrects.float())\n",
    "        enablePrint() \n",
    "        return loss + reg_loss, acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat.size() =  torch.Size([2, 240])\n",
      "next_mem.size() =  torch.Size([2, 1, 80])\n",
      "concat.size() =  torch.Size([2, 240])\n",
      "next_mem.size() =  torch.Size([2, 1, 80])\n",
      "concat.size() =  torch.Size([2, 240])\n",
      "next_mem.size() =  torch.Size([2, 1, 80])\n",
      "torch.Size([2, 1, 80])\n",
      "torch.Size([2, 1, 80])\n",
      "torch.Size([2, 22])\n",
      "actual answers size =  torch.Size([2])\n",
      "predicted answers size =  torch.Size([2, 22])\n",
      "loss size =  torch.Size([1])\n",
      "loss  =  Variable containing:\n",
      " 6.2372\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "self.parameters() =  <bound method Module.parameters of DMNPlus(\n",
      "  (word_embedding): Embedding(22, 80, padding_idx=0, sparse=True)\n",
      "  (criterion): CrossEntropyLoss(\n",
      "  )\n",
      ")>\n",
      "param.size()= torch.Size([22, 80])\n",
      "(param * param).size()= torch.Size([22, 80])\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinmittal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Users/sachinmittal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "model = DMNPlus(hidden_size, vocab_size, num_hop=3, qa=dset_train.QA)\n",
    "loss=model.get_loss(contexts, questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
