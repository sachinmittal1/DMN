{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from babi_loader import BabiDataset, pad_collate\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def interpret_indexed_tensor(var):\n",
    "    qa= dset.QA\n",
    "    if len(var.size()) == 3:\n",
    "        # var -> n x #sen x #token\n",
    "        for n, sentences in enumerate(var):\n",
    "            for i, sentence in enumerate(sentences):\n",
    "                s = ' '.join([qa.IVOCAB[elem.data[0]] for elem in sentence if qa.IVOCAB[elem.data[0]] != '<EOS>' or qa.IVOCAB[elem.data[0]] !=  '<PAD>'] )\n",
    "                print(f'{n}th of batch, {i}th sentence, {s}')\n",
    "    elif len(var.size()) == 2:\n",
    "        # var -> n x #token\n",
    "        for n, sentence in enumerate(var):\n",
    "            s = ' '.join([qa.IVOCAB[elem.data[0]] for elem in sentence if qa.IVOCAB[elem.data[0]] != '<EOS>' or qa.IVOCAB[elem.data[0]] !=  '<PAD>'] )\n",
    "            print(f'{n}th of batch, {s}')\n",
    "    elif len(var.size()) == 1:\n",
    "        # var -> n (one token per batch)\n",
    "        for n, token in enumerate(var):\n",
    "            s = qa.IVOCAB[token.data[0]]\n",
    "            print(f'{n}th of batch, {s}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from babi_loader import BabiDataset, pad_collate\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def position_encoding(embedded_sentence):\n",
    "    \n",
    "    sentence_length = embedded_sentence.size()[2]\n",
    "    embedding_length = embedded_sentence.size()[3]\n",
    "    shape = (embedding_length, sentence_length)\n",
    "    l = np.empty(shape)\n",
    "\n",
    "    for word_index in range(sentence_length):\n",
    "        for e_index in range(embedding_length):\n",
    "            l[e_index][word_index]=(1 - word_index/(sentence_length-1)) - (e_index/(embedding_length-1)) * (1 - 2*word_index/(sentence_length-1))\n",
    "    l=l.T\n",
    "    l = torch.FloatTensor(l)\n",
    "    l = l.unsqueeze(0) # for #batch\n",
    "    l = l.unsqueeze(1) # for #sen\n",
    "    print(\"embedded_sentence.size() = \",embedded_sentence.size())\n",
    "    print(\"before \",(l.size()))\n",
    "    l = l.expand_as(embedded_sentence)\n",
    "    print(\"after \",(l.size()))\n",
    "    weighted = embedded_sentence * Variable(l)\n",
    "    var = torch.sum(weighted, dim=2).squeeze(2)\n",
    "    print(\"return size\", var.size())\n",
    "    return torch.sum(weighted, dim=2).squeeze(2) # sum with tokens\n",
    "\n",
    "\n",
    "\n",
    "class AttentionGRUCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(AttentionGRUCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.Wr = nn.Linear(input_size, hidden_size)\n",
    "        init.xavier_normal(self.Wr.state_dict()['weight'])\n",
    "        self.Ur = nn.Linear(hidden_size, hidden_size)\n",
    "        init.xavier_normal(self.Ur.state_dict()['weight'])\n",
    "        self.W = nn.Linear(input_size, hidden_size)\n",
    "        init.xavier_normal(self.W.state_dict()['weight'])\n",
    "        self.U = nn.Linear(hidden_size, hidden_size)\n",
    "        init.xavier_normal(self.U.state_dict()['weight'])\n",
    "\n",
    "    def forward(self, fact, C, g):\n",
    "        '''\n",
    "        fact.size() -> (#batch, #hidden = #embedding)\n",
    "        c.size() -> (#hidden, ) -> (#batch, #hidden = #embedding)\n",
    "        r.size() -> (#batch, #hidden = #embedding)\n",
    "        h_tilda.size() -> (#batch, #hidden = #embedding)\n",
    "        g.size() -> (#batch, )\n",
    "        '''\n",
    "\n",
    "        r = F.sigmoid(self.Wr(fact) + self.Ur(C))\n",
    "        h_tilda = F.tanh(self.W(fact) + r * self.U(C))\n",
    "        g = g.unsqueeze(1).expand_as(h_tilda)\n",
    "        h = g * h_tilda + (1 - g) * C\n",
    "        return h\n",
    "\n",
    "class AttentionGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(AttentionGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.AGRUCell = AttentionGRUCell(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, facts, G):\n",
    "        '''\n",
    "        facts.size() -> (#batch, #sentence, #hidden = #embedding)\n",
    "        fact.size() -> (#batch, #hidden = #embedding)\n",
    "        G.size() -> (#batch, #sentence)\n",
    "        g.size() -> (#batch, )\n",
    "        C.size() -> (#batch, #hidden)\n",
    "        '''\n",
    "        batch_num, sen_num, embedding_size = facts.size()\n",
    "        C = Variable(torch.zeros(self.hidden_size))\n",
    "        for sid in range(sen_num):\n",
    "            fact = facts[:, sid, :]\n",
    "            g = G[:, sid]\n",
    "            if sid == 0:\n",
    "                C = C.unsqueeze(0).expand_as(fact)\n",
    "            C = self.AGRUCell(fact, C, g)\n",
    "        return C\n",
    "\n",
    "class EpisodicMemory(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(EpisodicMemory, self).__init__()\n",
    "        self.AGRU = AttentionGRU(hidden_size, hidden_size)\n",
    "        self.z1 = nn.Linear(4 * hidden_size, hidden_size)\n",
    "        self.z2 = nn.Linear(hidden_size, 1)\n",
    "        print(\"hi.....\")\n",
    "        self.next_mem = nn.Linear(3 * hidden_size, hidden_size)\n",
    "        init.xavier_normal(self.z1.state_dict()['weight'])\n",
    "        init.xavier_normal(self.z2.state_dict()['weight'])\n",
    "        init.xavier_normal(self.next_mem.state_dict()['weight'])\n",
    "\n",
    "    def make_interaction(self, facts, questions, prevM):\n",
    "        '''\n",
    "        facts.size() -> (#batch, #sentence, #hidden = #embedding)\n",
    "        questions.size() -> (#batch, 1, #hidden)\n",
    "        prevM.size() -> (#batch, #sentence = 1, #hidden = #embedding)\n",
    "        z.size() -> (#batch, #sentence, 4 x #embedding)\n",
    "        G.size() -> (#batch, #sentence)\n",
    "        '''\n",
    "        batch_num, sen_num, embedding_size = facts.size()\n",
    "        questions = questions.expand_as(facts)\n",
    "        prevM = prevM.expand_as(facts)\n",
    "\n",
    "        z = torch.cat([\n",
    "            facts * questions,\n",
    "            facts * prevM,\n",
    "            torch.abs(facts - questions),\n",
    "            torch.abs(facts - prevM)\n",
    "        ], dim=2)\n",
    "\n",
    "        z = z.view(-1, 4 * embedding_size)\n",
    "\n",
    "        G = F.tanh(self.z1(z))\n",
    "        G = self.z2(G)\n",
    "        G = G.view(batch_num, -1)\n",
    "        G = F.softmax(G)\n",
    "\n",
    "        return G\n",
    "\n",
    "    def forward(self, facts, questions, prevM):\n",
    "        '''\n",
    "        facts.size() -> (#batch, #sentence, #hidden = #embedding)\n",
    "        questions.size() -> (#batch, #sentence = 1, #hidden)\n",
    "        prevM.size() -> (#batch, #sentence = 1, #hidden = #embedding)\n",
    "        G.size() -> (#batch, #sentence)\n",
    "        C.size() -> (#batch, #hidden)\n",
    "        concat.size() -> (#batch, 3 x #embedding)\n",
    "        '''\n",
    "        G = self.make_interaction(facts, questions, prevM)\n",
    "        value, index = torch.max(G, dim=1)\n",
    "        print(\"attentions= \",G)\n",
    "        \n",
    "        print(\"focus = \")\n",
    "        print((index[0]))\n",
    "        #print(\"focus = \",interpret_indexed_tensor(contexts))\n",
    "        #print(\"focus = \",(value[0]))\n",
    "\n",
    "        C = self.AGRU(facts, G)\n",
    "        concat = torch.cat([prevM.squeeze(1), C, questions.squeeze(1)], dim=1)\n",
    "        next_mem = F.relu(self.next_mem(concat))\n",
    "        next_mem = next_mem.unsqueeze(1)\n",
    "        return next_mem\n",
    "\n",
    "\n",
    "class QuestionModule(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(QuestionModule, self).__init__()\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, questions, word_embedding):\n",
    "        '''\n",
    "        questions.size() -> (#batch, #token)\n",
    "        word_embedding() -> (#batch, #token, #embedding)\n",
    "        gru() -> (1, #batch, #hidden)\n",
    "        '''\n",
    "        questions = word_embedding(questions)\n",
    "        _, questions = self.gru(questions)\n",
    "        questions = questions.transpose(0, 1)\n",
    "        return questions\n",
    "\n",
    "class InputModule(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(InputModule, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, bidirectional=True, batch_first=True)\n",
    "        for name, param in self.gru.state_dict().items():\n",
    "            if 'weight' in name: init.xavier_normal(param)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, contexts, word_embedding):\n",
    "        '''\n",
    "        contexts.size() -> (#batch, #sentence, #token)\n",
    "        word_embedding() -> (#batch, #sentence x #token, #embedding)\n",
    "        position_encoding() -> (#batch, #sentence, #embedding)\n",
    "        facts.size() -> (#batch, #sentence, #hidden = #embedding)\n",
    "        '''\n",
    "        batch_num, sen_num, token_num = contexts.size()\n",
    "\n",
    "        contexts = contexts.view(batch_num, -1)\n",
    "        contexts = word_embedding(contexts)\n",
    "\n",
    "        contexts = contexts.view(batch_num, sen_num, token_num, -1)\n",
    "        contexts = position_encoding(contexts)\n",
    "        #print(\"contexts size = \",contexts.size())\n",
    "        #contexts = self.dropout(contexts)\n",
    "\n",
    "        h0 = Variable(torch.zeros(2, batch_num, self.hidden_size))\n",
    "        facts, hdn = self.gru(contexts, h0)\n",
    "        facts = facts[:, :, :hidden_size] + facts[:, :, hidden_size:]\n",
    "        #print(\"facts size = \",facts.size())\n",
    "        return facts\n",
    "\n",
    "class AnswerModule(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(AnswerModule, self).__init__()\n",
    "        self.z = nn.Linear(2 * hidden_size, vocab_size)\n",
    "        init.xavier_normal(self.z.state_dict()['weight'])\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, M, questions):\n",
    "        M = self.dropout(M)\n",
    "        concat = torch.cat([M, questions], dim=2).squeeze(1)\n",
    "        z = self.z(concat)\n",
    "        return z\n",
    "\n",
    "class DMNPlus(nn.Module):\n",
    "    def __init__(self, hidden_size, vocab_size, num_hop=3, qa=None):\n",
    "        super(DMNPlus, self).__init__()\n",
    "        self.num_hop = num_hop\n",
    "        self.qa = qa\n",
    "        self.word_embedding = nn.Embedding(vocab_size, hidden_size, padding_idx=0, sparse=True)\n",
    "        init.uniform(self.word_embedding.state_dict()['weight'], a=-(3**0.5), b=3**0.5)\n",
    "        self.criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "\n",
    "        self.input_module = InputModule(vocab_size, hidden_size)\n",
    "        self.question_module = QuestionModule(vocab_size, hidden_size)\n",
    "        self.memory = EpisodicMemory(hidden_size)\n",
    "        self.answer_module = AnswerModule(vocab_size, hidden_size)\n",
    "\n",
    "    def forward(self, contexts, questions):\n",
    "        '''\n",
    "        contexts.size() -> (#batch, #sentence, #token) -> (#batch, #sentence, #hidden = #embedding)\n",
    "        questions.size() -> (#batch, #token) -> (#batch, 1, #hidden)\n",
    "        '''\n",
    "        facts = self.input_module(contexts, self.word_embedding)\n",
    "        questions = self.question_module(questions, self.word_embedding)\n",
    "        M = questions\n",
    "        for hop in range(self.num_hop):\n",
    "            M = self.memory(facts, questions, M)\n",
    "        preds = self.answer_module(M, questions)\n",
    "        return preds\n",
    "\n",
    "   \n",
    "    def get_loss(self, contexts, questions, targets):\n",
    "        output = self.forward(contexts, questions)\n",
    "        loss = self.criterion(output, targets)\n",
    "        reg_loss = 0\n",
    "        for param in self.parameters():\n",
    "            reg_loss += 0.001 * torch.sum(param * param)\n",
    "        preds = F.softmax(output)\n",
    "        _, pred_ids = torch.max(preds, dim=1)\n",
    "        s = self.qa.IVOCAB[pred_ids.data[0]]\n",
    "        print(\"\\npredicted answer - \", s)\n",
    "        corrects = (pred_ids.data == answers.data)\n",
    "        acc = torch.mean(corrects.float())\n",
    "        return loss + reg_loss, acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi.....\n",
      "contexts -> \n",
      "0th of batch, 0th sentence, mary got the milk there . <EOS> <PAD>\n",
      "0th of batch, 1th sentence, john moved to the bedroom . <EOS> <PAD>\n",
      "0th of batch, 2th sentence, sandra went back to the kitchen . <EOS>\n",
      "0th of batch, 3th sentence, mary travelled to the hallway . <EOS> <PAD>\n",
      "\n",
      "\n",
      " questions -> \n",
      "0th of batch, where is the milk <EOS>\n",
      "\n",
      "\n",
      " answers -> \n",
      "0th of batch, hallway\n",
      "embedded_sentence.size() =  torch.Size([1, 4, 8, 80])\n",
      "before  torch.Size([1, 1, 8, 80])\n",
      "after  torch.Size([1, 4, 8, 80])\n",
      "return size torch.Size([1, 4, 80])\n",
      "attentions=  Variable containing:\n",
      " 6.6195e-06  9.4987e-04  1.4478e-04  9.9890e-01\n",
      "[torch.FloatTensor of size 1x4]\n",
      "\n",
      "focus = \n",
      "Variable containing:\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "attentions=  Variable containing:\n",
      " 0.0000  0.0013  0.0003  0.9984\n",
      "[torch.FloatTensor of size 1x4]\n",
      "\n",
      "focus = \n",
      "Variable containing:\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "attentions=  Variable containing:\n",
      " 0.0017  0.0102  0.0016  0.9865\n",
      "[torch.FloatTensor of size 1x4]\n",
      "\n",
      "focus = \n",
      "Variable containing:\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      "predicted answer -  hallway\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinmittal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:126: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Users/sachinmittal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:250: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    task_id = 2\n",
    "    dset = BabiDataset(task_id)\n",
    "    vocab_size = len(dset.QA.VOCAB)\n",
    "    hidden_size = 80\n",
    "    model = DMNPlus(hidden_size, vocab_size, num_hop=3, qa=dset.QA)\n",
    "    best_acc = 0\n",
    "    optim = torch.optim.Adam(model.parameters())\n",
    "    pretrained_dict_name = \"task\"+str(task_id)+\".pth\"\n",
    "    pretrained_dict = torch.load(pretrained_dict_name, map_location='cpu')\n",
    "    model_dict = model.state_dict()\n",
    "    #print(pretrained_dict.keys())\n",
    "    #print(\"\\n\\n\\n\")\n",
    "    #print(model_dict.keys())\n",
    "    dset.set_mode('test')\n",
    "    test_loader = DataLoader(\n",
    "        dset, batch_size=1, shuffle=False, collate_fn=pad_collate\n",
    "    )\n",
    "    test_acc = 0\n",
    "    cnt = 0\n",
    "\n",
    "    for batch_idx, data in enumerate(test_loader):\n",
    "        contexts, questions, answers = data\n",
    "        batch_size = contexts.size()[0]\n",
    "        contexts = Variable(contexts.long())\n",
    "        questions = Variable(questions.long())\n",
    "        answers = Variable(answers)\n",
    "        \n",
    "        print(\"contexts -> \")\n",
    "        interpret_indexed_tensor(contexts)\n",
    "        print(\"\\n\\n questions -> \")\n",
    "\n",
    "        interpret_indexed_tensor(questions)\n",
    "        print(\"\\n\\n answers -> \")\n",
    "\n",
    "        interpret_indexed_tensor(answers)\n",
    "\n",
    "\n",
    "        \n",
    "        model.load_state_dict(pretrained_dict)\n",
    "        \n",
    "        _, acc = model.get_loss(contexts, questions, answers)\n",
    "        #print(acc)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['word_embedding.weight', 'input_module.gru.weight_ih_l0', 'input_module.gru.weight_hh_l0', 'input_module.gru.bias_ih_l0', 'input_module.gru.bias_hh_l0', 'input_module.gru.weight_ih_l0_reverse', 'input_module.gru.weight_hh_l0_reverse', 'input_module.gru.bias_ih_l0_reverse', 'input_module.gru.bias_hh_l0_reverse', 'question_module.gru.weight_ih_l0', 'question_module.gru.weight_hh_l0', 'question_module.gru.bias_ih_l0', 'question_module.gru.bias_hh_l0', 'memory.AGRU.AGRUCell.Wr.weight', 'memory.AGRU.AGRUCell.Wr.bias', 'memory.AGRU.AGRUCell.Ur.weight', 'memory.AGRU.AGRUCell.Ur.bias', 'memory.AGRU.AGRUCell.W.weight', 'memory.AGRU.AGRUCell.W.bias', 'memory.AGRU.AGRUCell.U.weight', 'memory.AGRU.AGRUCell.U.bias', 'memory.z1.weight', 'memory.z1.bias', 'memory.z2.weight', 'memory.z2.bias', 'memory.next_mem.weight', 'memory.next_mem.bias', 'answer_module.z.weight', 'answer_module.z.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(pretrained_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
